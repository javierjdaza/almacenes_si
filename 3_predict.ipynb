{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s :: %(levelname)s :: %(message)s\")\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_by_week = pd.read_parquet('./datasets/curated/almacenes_si_curated_by_week.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saco archivo de descuentos que tiene la info de descuentos por familia, por semana \n",
    "discount_campaigns = df_grouped_by_week[df_grouped_by_week['date_week'].between(pd.to_datetime('2023-01-01'),pd.to_datetime('2023-12-31'))]\n",
    "discount_campaigns['familia'] = discount_campaigns['combination'].apply(lambda x: x[:3])\n",
    "discount_campaigns = discount_campaigns[['familia','date_week','discount_for_event', 'campaign']]\n",
    "discount_campaigns = discount_campaigns.groupby(['date_week'],as_index=False)['discount_for_event'].max()\n",
    "discount_campaigns['campaign'] = discount_campaigns['discount_for_event'].apply(lambda x: 1 if x != 0.0 else 0)\n",
    "discount_campaigns = discount_campaigns[['date_week', 'discount_for_event', 'campaign']]\n",
    "discount_campaigns.to_csv('./archivos_insumo/archivo_insumo_campañas_2023.csv', index = False)\n",
    "discount_campaigns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar fechas semanales para el año 2024, cada lunes\n",
    "dates = pd.date_range(start='2024-01-01', end='2024-12-31', freq='W-MON')\n",
    "\n",
    "# Generar valores aleatorios entre 0 y 70\n",
    "discount_for_event = np.random.randint(0, 71, size=len(dates))\n",
    "\n",
    "# Crear el DataFrame\n",
    "discount_campaigns = pd.DataFrame({'ds': dates, 'discount_for_event': discount_for_event})\n",
    "discount_campaigns['campaign'] = discount_campaigns['discount_for_event'].apply(lambda x: 1 if x != 0.0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_json(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        prophet_model = model_from_json(file.read())\n",
    "        \n",
    "    return prophet_model\n",
    "\n",
    "def make_predictions(model, future_regressors, year):\n",
    "    # Obtener la última fecha histórica\n",
    "    last_date = max(model.history_dates) + timedelta(weeks=1)\n",
    "    \n",
    "    # Crear un DataFrame con las fechas futuras hasta el año especificado, por semana comenzando en lunes\n",
    "    future_dates = pd.date_range(start=last_date, end=f'{year}-12-31', freq='W-MON')\n",
    "    \n",
    "    # Crear el DataFrame con las fechas y los regresores\n",
    "    future = pd.DataFrame({'ds': future_dates})\n",
    "    \n",
    "    # Añadir los regresores al DataFrame futuro\n",
    "    future = future.merge(future_regressors, how='left', on='ds')\n",
    "    \n",
    "    # Llenar NaNs con 0 si es necesario (asegúrate que esto tenga sentido para tu caso)\n",
    "    future.fillna(0, inplace=True)\n",
    "    \n",
    "    # Hacer la predicción\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    return forecast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo desde el archivo JSON\n",
    "model = load_model_from_json('./serialized_models/201AA3.json')\n",
    "\n",
    "# Hacer la predicción hasta el año 2025\n",
    "# future_regressors = discount_campaigns\n",
    "# forecast, future = make_predictions(model, future_regressors, 2024)\n",
    "# forecast[['ds', 'yhat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-12-25 00:00:00')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history['ds'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_campaigns.to_csv('./archivos_insumo/archivo_insumo_dummy_campañas_2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlmacenesSiModel:\n",
    "    \n",
    "    def __init__(self, serialized_models_path: str, campaigns_filepath: str, year_to_forecast: int, prior_year_sales_file_path: str):\n",
    "        self.serialized_models_path = serialized_models_path\n",
    "        self.year_to_forecast = year_to_forecast\n",
    "        self.campaigns_filepath = campaigns_filepath\n",
    "        \n",
    "        self.future_regressors = pd.read_csv(self.campaigns_filepath)\n",
    "        logging.info('Archivo de campañas cargado exitosamente ✅')\n",
    "        self.prior_year_sales_df = pd.read_csv(prior_year_sales_file_path)\n",
    "        logging.info(f'Archivo historico de ventas del año {self.year_to_forecast - 1} cargado exitosamente ✅')\n",
    "        self.future_regressors['ds'] = pd.to_datetime(self.future_regressors['ds'])\n",
    "        logging.info('Cargando datos del Modelo Predictivo ⌛')\n",
    "        self.models_info = self.get_keys_names_and_model()\n",
    "        logging.info('Modelo Predictivo cargado exitosamente ✅')\n",
    "        \n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def load_model_from_json(file_path):\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            prophet_model = model_from_json(file.read())\n",
    "        \n",
    "        return prophet_model    \n",
    "    \n",
    "    @staticmethod\n",
    "    def make_predictions(model, future_regressors : pd.DataFrame, year : int)->pd.DataFrame:\n",
    "        # Obtener la última fecha histórica\n",
    "        last_date = max(model.history_dates) + timedelta(weeks=1)\n",
    "        \n",
    "        # Crear un DataFrame con las fechas futuras hasta el año especificado, por semana comenzando en lunes\n",
    "        future_dates = pd.date_range(start=last_date, end=f'{year}-12-31', freq='W-MON')\n",
    "        \n",
    "        # Crear el DataFrame con las fechas y los regresores\n",
    "        future = pd.DataFrame({'ds': future_dates})\n",
    "        \n",
    "        # Añadir los regresores al DataFrame futuro\n",
    "        future = future.merge(future_regressors, how='left', on='ds')\n",
    "        \n",
    "        # Llenar NaNs con 0 si es necesario \n",
    "        future.fillna(0, inplace=True)\n",
    "        \n",
    "        # Hacer la predicción\n",
    "        forecast = model.predict(future)\n",
    "        \n",
    "        return forecast[['ds', 'yhat']]\n",
    "    \n",
    "    def get_keys_names_and_model(self):\n",
    "        \n",
    "        models_info = {}\n",
    "        for model_path in tqdm(glob(f'{self.serialized_models_path}/*.json')):\n",
    "            \n",
    "            key_name = str(os.path.basename(model_path).split('.')[0].strip())\n",
    "            model_temp = self.load_model_from_json(model_path)\n",
    "            models_info[key_name] = model_temp\n",
    "            \n",
    "        return models_info\n",
    "        \n",
    "    def get_all_keys_prediction(self):\n",
    "        \n",
    "        forecast_df = pd.DataFrame()\n",
    "        \n",
    "        logging.info(f'Calculando Predicciones para el año {self.year_to_forecast} ⌛')\n",
    "        for key, model in tqdm(self.models_info.items()):\n",
    "            \n",
    "            PARAMS = {\n",
    "                'model' : model,\n",
    "                'future_regressors' : self.future_regressors,\n",
    "                'year' : self.year_to_forecast\n",
    "            }\n",
    "            try:\n",
    "                forecast_temp = self.make_predictions(**PARAMS )\n",
    "                forecast_temp['llave'] = key\n",
    "                forecast_df = pd.concat([forecast_df,forecast_temp])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "        self.forecast_df = forecast_df\n",
    "        self.forecast_df.rename(columns = {'ds' : 'fecha','yhat' : 'prediccion_demanda'}, inplace = True)\n",
    "        return forecast_df\n",
    "    \n",
    "    \n",
    "    def calculate_store_breakdown(self):\n",
    "        \n",
    "        forecast_df = self.forecast_df\n",
    "        prior_year_sales_df = self.prior_year_sales_df\n",
    "        forecast_df['fecha'] = pd.to_datetime(forecast_df['fecha'])\n",
    "        forecast_df['semana'] = pd.to_datetime(forecast_df['fecha']).apply(lambda x: x.strftime('%-W'))\n",
    "\n",
    "        prior_year_sales_df['date'] = pd.to_datetime(prior_year_sales_df['date'])\n",
    "        prior_year_sales_df['week'] = prior_year_sales_df['date'].apply(lambda x: x.strftime('%-W'))\n",
    "        \n",
    "        self.demanda_desagrada_por_tienda = pd.DataFrame()\n",
    "        year_prediction = int(forecast_df['fecha'].max().strftime('%Y'))\n",
    "        for semana in forecast_df['semana'].unique(): # recorro todas las llaves disponibles en la prediccion\n",
    "            logging.info(f'semana: {semana}')\n",
    "            llaves_to_explore = forecast_df[forecast_df['semana'] == semana]['llave'].unique()# saco todas las llaves a explorar en la semana T\n",
    "            df_week_selected =  prior_year_sales_df[(prior_year_sales_df['week'] == semana)] # saco la informacion del ultimo año disponible en la semana T\n",
    "            # ------------------\n",
    "            for llave in tqdm(llaves_to_explore): # recorro todas las llaves disponibles en la semana T\n",
    "\n",
    "                demanda_forecast = forecast_df[(forecast_df['semana'] == semana) & (forecast_df['llave'] == llave)]['prediccion_demanda'] # calculo de la prediccion de la demanda para X llave\n",
    "                demanda_forecast = np.ceil(demanda_forecast.iat[0]) # redondeo de la prediccion\n",
    "                df_week_key_selected = df_week_selected[df_week_selected['combination'] == llave] # filtrado de la cantidad de unidades vendidad para la semana T para la llave X en el ultimo año de data\n",
    "                if len(df_week_key_selected) > 0:\n",
    "                    data_grouped_by_store = df_week_key_selected.groupby(['store_id'], as_index=False)['quantity'].sum() # calculo de cuantas unidades se vendieron por tienda en la semana T para la llave X\n",
    "                    store_proportion = data_grouped_by_store.copy()\n",
    "                    store_proportion['proportion'] = round(store_proportion['quantity'] / (store_proportion['quantity'].sum()),2) # calculo de porcentaje de las unidades vendidas por tienda, en la semana T para la llave X\n",
    "                    store_proportion = store_proportion[store_proportion['proportion'] != 0] # remover aquellas tiendas que no vendieron ninguna unidad de la llave X para la semana T\n",
    "                    store_proportion['forecast_llave'] = demanda_forecast\n",
    "                    store_proportion['demanda'] = store_proportion['forecast_llave'] * store_proportion['proportion'] # multiplico la proporcion de ventas la llave X en la semana T para cada tienda, segun pronostico\n",
    "                    store_proportion['demanda'] = store_proportion['demanda'].apply(lambda x: np.ceil(x)) # redondeo de la prediccion\n",
    "                    temp_store_key_prediction = store_proportion.copy()\n",
    "                    temp_store_key_prediction = temp_store_key_prediction[['store_id','demanda']]\n",
    "                    temp_store_key_prediction['llave'] = llave\n",
    "                    temp_store_key_prediction['week'] = semana\n",
    "                    temp_store_key_prediction['year'] = year_prediction\n",
    "                    self.demanda_desagrada_por_tienda = pd.concat([self.demanda_desagrada_por_tienda,temp_store_key_prediction])\n",
    "                    \n",
    "        return self.demanda_desagrada_por_tienda\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'serialized_models_path' : './serialized_models',\n",
    "    'campaigns_filepath' : './archivos_insumo/archivo_insumo_dummy_campañas_2024.csv',\n",
    "    'prior_year_sales_file_path' : './datasets/historico_ventas_2023_semanal.csv',\n",
    "    'year_to_forecast' : 2024,\n",
    "}\n",
    "x = AlmacenesSiModel(**PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = x.get_all_keys_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-01-07 00:00:00')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast['fecha'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demanda_desagrada_por_tienda = x.calculate_store_breakdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date = max(model.history_dates) + timedelta(weeks=1)\n",
    "year = 2024\n",
    "# Crear un DataFrame con las fechas futuras hasta el año especificado, por semana comenzando en lunes\n",
    "future_dates = pd.date_range(start=last_date, end=f'{year}-12-31', freq='W-MON')\n",
    "\n",
    "# Crear el DataFrame con las fechas y los regresores\n",
    "future = pd.DataFrame({'ds': future_dates})\n",
    "\n",
    "# Añadir los regresores al DataFrame futuro\n",
    "archivos_insumo = pd.read_csv('./archivos_insumo/archivo_insumo_dummy_campañas_2024.csv')\n",
    "archivos_insumo['ds'] = pd.to_datetime(archivos_insumo['ds'])\n",
    "future = future.merge(archivos_insumo, how='left', on='ds')\n",
    "\n",
    "# Llenar NaNs con 0 si es necesario \n",
    "future.fillna(0, inplace=True)\n",
    "\n",
    "# Hacer la predicción\n",
    "forecast = model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-01-01 00:00:00')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.ds.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from datetime import date\n",
    "from llaves_more_then_q95 import llaves_more_then_q95\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "\n",
    "# Set the logging level for cmdstanpy to WARNING\n",
    "logging.getLogger('cmdstanpy').setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_by_week = pd.read_parquet('./datasets/almacenes_si_curated_by_week.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combination</th>\n",
       "      <th>date_week</th>\n",
       "      <th>quantity</th>\n",
       "      <th>discount_for_event</th>\n",
       "      <th>campaigns_name</th>\n",
       "      <th>price_taxes_excluded</th>\n",
       "      <th>campaign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170356</th>\n",
       "      <td>248AI6QJ6T10</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no-discount</td>\n",
       "      <td>23521.009766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170357</th>\n",
       "      <td>248AI6QJ6T10</td>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no-discount</td>\n",
       "      <td>92403.359375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170358</th>\n",
       "      <td>248AI6QJ6T10</td>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no-discount</td>\n",
       "      <td>46201.679688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170359</th>\n",
       "      <td>248AI6QJ6T10</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no-discount</td>\n",
       "      <td>69722.687500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170360</th>\n",
       "      <td>248AI6QJ6T10</td>\n",
       "      <td>2018-02-19</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TIJERETAZO I</td>\n",
       "      <td>115924.367188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170431</th>\n",
       "      <td>248AI6QJ6T10</td>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TIJERETAZO I</td>\n",
       "      <td>36546.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170432</th>\n",
       "      <td>248AI6QJ6T10</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TIJERETAZO I</td>\n",
       "      <td>34193.281250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170433</th>\n",
       "      <td>248AI6QJ6T10</td>\n",
       "      <td>2023-03-20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TIJERETAZO I</td>\n",
       "      <td>34193.281250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170434</th>\n",
       "      <td>248AI6QJ6T10</td>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no-discount</td>\n",
       "      <td>70739.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170435</th>\n",
       "      <td>248AI6QJ6T10</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DCTO ESTELAR</td>\n",
       "      <td>70739.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         combination  date_week  quantity  discount_for_event campaigns_name  \\\n",
       "170356  248AI6QJ6T10 2018-01-08         1                 0.0    no-discount   \n",
       "170357  248AI6QJ6T10 2018-01-15         5                 0.0    no-discount   \n",
       "170358  248AI6QJ6T10 2018-01-29         2                 0.0    no-discount   \n",
       "170359  248AI6QJ6T10 2018-02-05         5                 0.0    no-discount   \n",
       "170360  248AI6QJ6T10 2018-02-19         5                 0.0   TIJERETAZO I   \n",
       "...              ...        ...       ...                 ...            ...   \n",
       "170431  248AI6QJ6T10 2023-02-27         1                 0.0   TIJERETAZO I   \n",
       "170432  248AI6QJ6T10 2023-03-06         2                 0.0   TIJERETAZO I   \n",
       "170433  248AI6QJ6T10 2023-03-20         1                 0.0   TIJERETAZO I   \n",
       "170434  248AI6QJ6T10 2023-03-27         2                 0.0    no-discount   \n",
       "170435  248AI6QJ6T10 2023-04-10         2                 0.0   DCTO ESTELAR   \n",
       "\n",
       "        price_taxes_excluded  campaign  \n",
       "170356          23521.009766         0  \n",
       "170357          92403.359375         0  \n",
       "170358          46201.679688         0  \n",
       "170359          69722.687500         0  \n",
       "170360         115924.367188         1  \n",
       "...                      ...       ...  \n",
       "170431          36546.000000         1  \n",
       "170432          34193.281250         1  \n",
       "170433          34193.281250         1  \n",
       "170434          70739.500000         0  \n",
       "170435          70739.500000         1  \n",
       "\n",
       "[80 rows x 7 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped_by_week[df_grouped_by_week['combination'] == '248AI6QJ6T10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_by_week.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_insumo = df_grouped_by_week[['date_week','combination','campaign','discount_for_event']]\n",
    "archivo_insumo = archivo_insumo[archivo_insumo['date_week'].between('2023-01-01','2023-12-31')]\n",
    "archivo_insumo['familia'] = archivo_insumo['combination'].apply(lambda x: str(x)[:3])\n",
    "archivo_insumo = archivo_insumo.groupby(['date_week','familia'], as_index=False)[['discount_for_event','campaign']].max()\n",
    "archivo_insumo = archivo_insumo[['familia','date_week','discount_for_event','campaign']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_insumo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_campanias = df_grouped_by_week[['date_week','combination','campaign','discount_for_event']]\n",
    "archivo_campanias['familia'] = archivo_campanias['combination'].apply(lambda x: str(x)[:3])\n",
    "archivo_campanias = archivo_campanias.groupby(['date_week','familia'], as_index=False)[['discount_for_event','campaign']].max()\n",
    "archivo_campanias = archivo_campanias[['familia','date_week','discount_for_event','campaign']]\n",
    "archivo_campanias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llaves_con_informacion_historica_suficiente_para_forecast = []\n",
    "combinations_to_forecast = df_grouped_by_week['combination'].unique()\n",
    "for combination in tqdm(combinations_to_forecast):\n",
    "    df_combination = df_grouped_by_week[df_grouped_by_week['combination'] == combination]\n",
    "    if len(df_combination[df_combination['date_week'] >= '2022-01-01']) >= 12: # si tiene por lo menos 12 semanas desde el 2022\n",
    "        llaves_con_informacion_historica_suficiente_para_forecast.append(combination)\n",
    "print(len(llaves_con_informacion_historica_suficiente_para_forecast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combination</th>\n",
       "      <th>date_week</th>\n",
       "      <th>quantity</th>\n",
       "      <th>discount_for_event</th>\n",
       "      <th>campaigns_name</th>\n",
       "      <th>price_taxes_excluded</th>\n",
       "      <th>campaign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57230</th>\n",
       "      <td>240AG7PA5</td>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>13</td>\n",
       "      <td>40.0</td>\n",
       "      <td>BLACK WEEK</td>\n",
       "      <td>109235.289062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57231</th>\n",
       "      <td>240AG7PA5</td>\n",
       "      <td>2023-08-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no-discount</td>\n",
       "      <td>54617.648438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57232</th>\n",
       "      <td>240AG7PA5</td>\n",
       "      <td>2023-09-04</td>\n",
       "      <td>4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>TIJERETAZO II</td>\n",
       "      <td>128557.140625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57233</th>\n",
       "      <td>240AG7PA5</td>\n",
       "      <td>2023-09-11</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>TIJERETAZO II</td>\n",
       "      <td>37810.921875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57234</th>\n",
       "      <td>240AG7PA5</td>\n",
       "      <td>2023-09-25</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>TIJERETAZO II</td>\n",
       "      <td>37810.921875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57235</th>\n",
       "      <td>240AG7PA5</td>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>TIJERETAZO II</td>\n",
       "      <td>128557.140625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57236</th>\n",
       "      <td>240AG7PA5</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no-discount</td>\n",
       "      <td>45373.109375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57237</th>\n",
       "      <td>240AG7PA5</td>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no-discount</td>\n",
       "      <td>75621.851562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57238</th>\n",
       "      <td>240AG7PA5</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no-discount</td>\n",
       "      <td>54617.648438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57239</th>\n",
       "      <td>240AG7PA5</td>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no-discount</td>\n",
       "      <td>75621.851562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57240</th>\n",
       "      <td>240AG7PA5</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>CRAZY SANTA</td>\n",
       "      <td>113432.765625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57241</th>\n",
       "      <td>240AG7PA5</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>CRAZY SANTA</td>\n",
       "      <td>37810.921875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57242</th>\n",
       "      <td>240AG7PA5</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>CRAZY SANTA</td>\n",
       "      <td>37810.921875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57243</th>\n",
       "      <td>240AG7PA5</td>\n",
       "      <td>2023-12-25</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>CRAZY SANTA</td>\n",
       "      <td>37810.921875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      combination  date_week  quantity  discount_for_event campaigns_name  \\\n",
       "57230   240AG7PA5 2022-11-28        13                40.0     BLACK WEEK   \n",
       "57231   240AG7PA5 2023-08-07         1                 0.0    no-discount   \n",
       "57232   240AG7PA5 2023-09-04         4                35.0  TIJERETAZO II   \n",
       "57233   240AG7PA5 2023-09-11         1                35.0  TIJERETAZO II   \n",
       "57234   240AG7PA5 2023-09-25         2                35.0  TIJERETAZO II   \n",
       "57235   240AG7PA5 2023-10-02         5                35.0  TIJERETAZO II   \n",
       "57236   240AG7PA5 2023-10-16         1                 0.0    no-discount   \n",
       "57237   240AG7PA5 2023-10-23         1                 0.0    no-discount   \n",
       "57238   240AG7PA5 2023-10-30         1                 0.0    no-discount   \n",
       "57239   240AG7PA5 2023-11-13         1                 0.0    no-discount   \n",
       "57240   240AG7PA5 2023-11-27         4                35.0    CRAZY SANTA   \n",
       "57241   240AG7PA5 2023-12-04         4                35.0    CRAZY SANTA   \n",
       "57242   240AG7PA5 2023-12-11         1                35.0    CRAZY SANTA   \n",
       "57243   240AG7PA5 2023-12-25         2                35.0    CRAZY SANTA   \n",
       "\n",
       "       price_taxes_excluded  campaign  \n",
       "57230         109235.289062         1  \n",
       "57231          54617.648438         0  \n",
       "57232         128557.140625         1  \n",
       "57233          37810.921875         1  \n",
       "57234          37810.921875         1  \n",
       "57235         128557.140625         1  \n",
       "57236          45373.109375         0  \n",
       "57237          75621.851562         0  \n",
       "57238          54617.648438         0  \n",
       "57239          75621.851562         0  \n",
       "57240         113432.765625         1  \n",
       "57241          37810.921875         1  \n",
       "57242          37810.921875         1  \n",
       "57243          37810.921875         1  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped_by_week[df_grouped_by_week['combination'] == combination]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3337 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 67/3337 [00:21<16:07,  3.38it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219301AC1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 71/3337 [00:22<13:30,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219301AU4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 250/3337 [01:29<10:07,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problems with this key: 240AG7PA5\n",
      "Dataframe has less than 2 non-NaN rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 348/3337 [01:51<08:02,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240BC5PC6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 372/3337 [01:56<20:08,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240BP9PC4\n",
      "240BP9PD4\n",
      "240BP9PD6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 385/3337 [01:58<08:24,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240BT4PD8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 453/3337 [02:17<15:27,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242550AW1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 488/3337 [02:32<20:15,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247AY1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 557/3337 [03:06<08:43,  5.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248AF5PT7T12\n",
      "248AF5PT7T14\n",
      "248AF5PT7T16\n",
      "248AF5PT7TL\n",
      "248AF5PT7TM\n",
      "248AF5PT7TS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 611/3337 [03:41<28:33,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248AF5QC5T16\n",
      "248AF5QC5TM\n",
      "248AF5QC5TS\n",
      "248AF5QC5TXL\n",
      "248AF5QD1T16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 688/3337 [04:14<04:05, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248AF5QT1T08\n",
      "248AF5QT1T10\n",
      "248AF5QT1T12\n",
      "248AF5QT1T14\n",
      "248AF5QT1T16\n",
      "248AF5QT1TL\n",
      "248AF5QT1TM\n",
      "248AF5QT1TS\n",
      "248AF5QT3T14\n",
      "248AF5QT3T16\n",
      "248AF5QT3TM\n",
      "248AF5QT3TS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1585/3337 [14:18<18:54,  1.54it/s]"
     ]
    }
   ],
   "source": [
    "final_prediction_2023 = pd.DataFrame()\n",
    "rmse_por_llave = pd.DataFrame()\n",
    "test_model = True\n",
    "\n",
    "for combination in tqdm(llaves_con_informacion_historica_suficiente_para_forecast):\n",
    "\n",
    "    # Get the dataframe for the combination\n",
    "    df_combination = df_grouped_by_week[df_grouped_by_week['combination'] == combination]\n",
    "    df_combination = df_combination[['date_week','combination','quantity']]\n",
    "    \n",
    "    if combination in llaves_more_then_q95 and len(df_combination[df_combination['date_week'] >= '2022-01-01']) > 0: # si la llave esta en las llaves q95 y tiene data en el 2022, se entrena con data 2022, de lo contrario, se entra con todo lo disponible\n",
    "        df_combination = df_combination[df_combination['date_week'] >= '2022-01-01']\n",
    "    # df_combination_test = df_grouped_by_week_test[df_grouped_by_week_test['combination'] == combination][['date_week','quantity','campaign','discount_for_event']] # get the y_true values of the combination selected\n",
    "\n",
    "    familia = str(combination[:3])\n",
    "    df_discount_and_campaings = archivo_campanias[archivo_campanias['familia'] == familia]\n",
    "\n",
    "    # df_discount_and_campaings = df_grouped_by_week[df_grouped_by_week['date_week'] >= '2024-01-01']\n",
    "    # df_discount_and_campaings = df_discount_and_campaings[['combination','date_week','discount_for_event','campaign']]\n",
    "    # Complete the missing weeks with 0\n",
    "    first_date = df_combination['date_week'].min() # Get the first date in the dataframe\n",
    "    last_date = df_combination['date_week'].max() # Get the last date in the dataframe\n",
    "    \n",
    "    if test_model == True and first_date.year <= 2022:\n",
    "        # Create a dataframe with all the weeks between the year of the first date and the year of the last date\n",
    "        df_dates = pd.DataFrame({'date_week': pd.date_range(start=f'{first_date.year}-01-08', end=f'2022-12-31', freq='W-MON')})    \n",
    "\n",
    "        df_combination = df_dates.merge(df_combination, on='date_week', how='left') # Merge the dataframes\n",
    "        df_combination['quantity'] = df_combination['quantity'].fillna(0) # Replace NaN values with 0\n",
    "        df_combination = df_combination[~(df_combination['combination'].isnull())]\n",
    "        df_combination = df_combination.merge(df_discount_and_campaings, on='date_week', how='left') # Merge the dataframes\n",
    "\n",
    "        # Create the prophet dataframe\n",
    "        prophet_dataframe = pd.DataFrame()\n",
    "        prophet_dataframe['ds'] = df_combination['date_week']\n",
    "        prophet_dataframe['y'] = df_combination['quantity']\n",
    "        prophet_dataframe['campaign'] = df_combination['campaign']\n",
    "        prophet_dataframe['discount_for_event'] = df_combination['discount_for_event']\n",
    "        prophet_dataframe['y'] = prophet_dataframe['y'].astype(int)\n",
    "\n",
    "        n_unique_years = prophet_dataframe['ds'].dt.year.nunique() # Count the number of different years in the dataframe\n",
    "\n",
    "        # Create the model\n",
    "        if n_unique_years == 1:\n",
    "            model = Prophet(weekly_seasonality = 13)\n",
    "            model.add_regressor('campaign')\n",
    "            model.add_regressor('discount_for_event')\n",
    "\n",
    "        else:\n",
    "            model = Prophet(weekly_seasonality = 52)\n",
    "            model.add_regressor('campaign')\n",
    "            model.add_regressor('discount_for_event')\n",
    "            \n",
    "            \n",
    "        try:\n",
    "            model.fit(prophet_dataframe)\n",
    "            with open(f'./serialized_models/{str(combination)}.json', 'w') as file:\n",
    "                file.write(model_to_json(model))  # Save model\n",
    "            \n",
    "            \n",
    "            if test_model:\n",
    "                # Calculate how many weeks are missing from the last date in the dataframe to the last week of 2023\n",
    "                weeks = (date(2023, 12, 31) - prophet_dataframe['ds'].max().date()).days // 7\n",
    "\n",
    "                # Create a dataframe with the dates from the last date in the dataframe to the last week of 2023\n",
    "                df_grouped_by_week_test = df_grouped_by_week[df_grouped_by_week['date_week'].between('2023-01-01','2023-12-31')]\n",
    "                df_combination_test = df_grouped_by_week_test[df_grouped_by_week_test['combination'] == combination][['date_week','quantity']] # get the y_true values of the combination selected\n",
    "                df_combination_test = df_combination_test.merge(df_discount_and_campaings, on='date_week', how='left') # Merge the dataframes\n",
    "\n",
    "                future_2023 = model.make_future_dataframe(periods=weeks, freq='W-MON')\n",
    "                future_2023 = future_2023[future_2023['ds'] >= '2023-01-01']\n",
    "                future_2023 = future_2023.merge(df_combination_test, right_on='date_week',left_on= 'ds', how = 'left')\n",
    "                del future_2023['date_week']\n",
    "                future_2023['familia'] = familia\n",
    "                future_2023['campaign'].fillna(0,inplace=True)\n",
    "                future_2023['quantity'].fillna(0,inplace=True)\n",
    "                future_2023['discount_for_event'].fillna(0,inplace=True)\n",
    "                \n",
    "                \n",
    "                forecast = model.predict(future_2023) # Make the predictions\n",
    "                forecast_2023 = forecast[['ds', 'yhat']] # Get the predictions for 2023\n",
    "                forecast_2023.columns = ['date', 'demand_yhat'] # Rename columns\n",
    "                forecast_2023['llave'] = combination # Add the combination column\n",
    "                # Add to the final predictions dataframe\n",
    "                final_prediction_2023 = pd.concat([final_prediction_2023, forecast_2023])\n",
    "                final_prediction_2023['demand_yhat'] = final_prediction_2023['demand_yhat'].apply(lambda x: 0 if x < 0 else x)\n",
    "                final_prediction_2023['demand_yhat'] = final_prediction_2023['demand_yhat'].apply(lambda x: np.ceil(x))\n",
    "\n",
    "                X_test = df_grouped_by_week[df_grouped_by_week['combination'] == combination][['date_week','quantity']]\n",
    "                X_test.columns = ['date','y_true']\n",
    "                df_ytrue_yhat = final_prediction_2023.merge(X_test,on= 'date', how = 'left')\n",
    "                df_ytrue_yhat['y_true'].fillna(0, inplace=True)\n",
    "\n",
    "                RMSE = np.sqrt(mean_squared_error(df_ytrue_yhat['y_true'], df_ytrue_yhat['demand_yhat']))\n",
    "                dict_temp = {\n",
    "                    'llave' : combination,\n",
    "                    'rsme' : RMSE\n",
    "                }\n",
    "                df_rmse = pd.DataFrame([dict_temp])\n",
    "                rmse_por_llave = pd.concat([rmse_por_llave,df_rmse])\n",
    "        except Exception as e:\n",
    "            print(f'problems with this key: {combination}\\n{e}')\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    else:\n",
    "        print(combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_por_llave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # # -----------------------------------------------------------------------------------\n",
    "    # # Do the same to generate de prophet_df, but with test data(2023) to compare results\n",
    "    # # -----------------------------------------------------------------------------------\n",
    "    # # Complete the missing weeks with 0\n",
    "    # first_date_test = df_combination_test['date_week'].min() # Get the first date in the dataframe\n",
    "    # last_date_test = df_combination_test['date_week'].max() # Get the last date in the dataframe\n",
    "    # # Create a dataframe with all the weeks between the year of the first date and the year of the last date\n",
    "    # df_dates_test = pd.DataFrame({'date_week': pd.date_range(start=f'{first_date_test.year}-01-08', end=f'{last_date_test.year}-12-31', freq='W-MON')})    \n",
    "    # df_combination_test = df_dates_test.merge(df_combination_test, on='date_week', how='left') # Merge the dataframes\n",
    "    # df_combination_test['quantity'] = df_combination_test['quantity'].fillna(0) # Replace NaN values with 0\n",
    "    # df_combination_test = df_combination_test[df_combination_test['date_week'] < '2024-01-01'] # Drop registers from 2024\n",
    "    \n",
    "    # # Create the prophet TEST dataframe\n",
    "    # dataframe_test = pd.DataFrame()\n",
    "    # dataframe_test['ds'] = df_combination_test['date_week']\n",
    "    # dataframe_test['y_true'] = df_combination_test['quantity']\n",
    "\n",
    "    # # Merge the forecast_2024 with the y_true values\n",
    "    # prediction = forecast[['ds', 'yhat']].merge(dataframe_test, on='ds', how='left')\n",
    "    # prediction = prediction[prediction['ds'] >= '2023-01-01']\n",
    "    # prediction['y_true'] = prediction['y_true'].fillna(0) # Fill NaN values with 0\n",
    "    # prediction['y_true'] = prediction['y_true'].astype(int)\n",
    "    # prediction['yhat'] = prediction['yhat'].apply(lambda x: 0 if x < 0 else x) # Replace negative values with 0\n",
    "    \n",
    "    \n",
    "    # # Calculate the rsme for test_set\n",
    "    # df_rsme = prediction.copy()\n",
    "    # rsme = np.sqrt(mean_squared_error(df_rsme['y_true'], df_rsme['yhat']))\n",
    "    \n",
    "    # # generate new column error with the abs(error)\n",
    "    # prediction['error'] = prediction['y_true'] - prediction['yhat']\n",
    "    # prediction['error'] = prediction['error'].apply(lambda x: abs(x))\n",
    "    # prediction['llave'] = combination\n",
    "    # final_prediction_2024_with_test_data = pd.concat([final_prediction_2024_with_test_data,prediction])\n",
    "    # rmse_por_llave = {\n",
    "    #     'llave': combination,\n",
    "    #     'rmse' : rsme\n",
    "    # }\n",
    "    # rmse_por_llave_resultados.append(rmse_por_llave)\n",
    "    with open(f'.././serialized_models/{str(combination)}.json', 'w') as file:\n",
    "        file.write(model_to_json(model))  # Save model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction_2024 = pd.DataFrame()\n",
    "final_prediction_2024_with_test_data = pd.DataFrame()\n",
    "rmse_por_llave_resultados = []\n",
    "# Get the list of combinations\n",
    "for combination in tqdm(llaves_con_informacion_historica_suficiente_para_forecast):\n",
    "    # Get the dataframe for the combination\n",
    "    df_combination = df_grouped_by_week[df_grouped_by_week['combination'] == combination]\n",
    "    if combination in llaves_more_then_q95 and len(df_combination[df_combination['date_week'] >= '2022-01-01']) > 0: # si la llave esta en las llaves q95 y tiene data en el 2022, se entrena con data 2022, de lo contrario, se entra con todo lo disponible\n",
    "        df_combination = df_combination[df_combination['date_week'] >= '2022-01-01']\n",
    "    # df_combination_test = df_grouped_by_week_test[df_grouped_by_week_test['combination'] == combination][['date_week','quantity','campaign','discount_for_event']] # get the y_true values of the combination selected\n",
    "    df_discount_and_campaings = df_grouped_by_week[df_grouped_by_week['date_week'] >= '2024-01-01']\n",
    "    df_discount_and_campaings = df_discount_and_campaings[['combination','date_week','discount_for_event','campaign']]\n",
    "    # Complete the missing weeks with 0\n",
    "    first_date = df_combination['date_week'].min() # Get the first date in the dataframe\n",
    "    last_date = df_combination['date_week'].max() # Get the last date in the dataframe\n",
    "    # Create a dataframe with all the weeks between the year of the first date and the year of the last date\n",
    "    df_dates = pd.DataFrame({'date_week': pd.date_range(start=f'{first_date.year}-01-08', end=f'{last_date.year}-12-31', freq='W-MON')})    \n",
    "    \n",
    "    df_combination = df_dates.merge(df_combination, on='date_week', how='left') # Merge the dataframes\n",
    "    df_combination['quantity'] = df_combination['quantity'].fillna(0) # Replace NaN values with 0\n",
    "    df_combination['campaign'] = df_combination['campaign'].fillna(0) # Replace NaN values with 0\n",
    "    df_combination['discount_for_event'] = df_combination['discount_for_event'].fillna(0) # Replace NaN values with 0\n",
    "\n",
    "    df_combination = df_combination[df_combination['date_week'] < '2023-12-31'] # Drop registers from 2024\n",
    "\n",
    "    # Create the prophet dataframe\n",
    "    prophet_dataframe = pd.DataFrame()\n",
    "    prophet_dataframe['ds'] = df_combination['date_week']\n",
    "    prophet_dataframe['y'] = df_combination['quantity']\n",
    "    prophet_dataframe['campaign'] = df_combination['campaign']\n",
    "    prophet_dataframe['discount_for_event'] = df_combination['discount_for_event']\n",
    "    prophet_dataframe['y'] = prophet_dataframe['y'].astype(int)\n",
    "\n",
    "    n_unique_years = prophet_dataframe['ds'].dt.year.nunique() # Count the number of different years in the dataframe\n",
    "\n",
    "    # Create the model\n",
    "    if n_unique_years == 1:\n",
    "        model = Prophet(weekly_seasonality = 13)\n",
    "        model.add_regressor('campaign')\n",
    "        model.add_regressor('discount_for_event')\n",
    "\n",
    "    else:\n",
    "        model = Prophet(weekly_seasonality = 52)\n",
    "        model.add_regressor('campaign')\n",
    "        model.add_regressor('discount_for_event')\n",
    "        \n",
    "        \n",
    "    model.fit(prophet_dataframe)\n",
    "\n",
    "    # Calculate how many weeks are missing from the last date in the dataframe to the last week of 2023\n",
    "    weeks = (date(2024, 12, 31) - prophet_dataframe['ds'].max().date()).days // 7\n",
    "    # Create a dataframe with the dates from the last date in the dataframe to the last week of 2023\n",
    "    future_2024 = model.make_future_dataframe(periods=weeks, freq='W-MON')\n",
    "    future_2024 = future_2024[future_2024['ds'] >= '2024-01-01']\n",
    "    future_2024 = future_2024.merge(df_combination_test, right_on='date_week',left_on= 'ds', how = 'left')\n",
    "    del future_2024['date_week']\n",
    "    future_2024[['quantity','campaign','discount_for_event']] = future_2024[['quantity','campaign','discount_for_event']].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "    forecast = model.predict(future_2024) # Make the predictions\n",
    "    forecast_2024 = forecast[['ds', 'yhat']] # Get the predictions for 2023\n",
    "    forecast_2024.columns = ['date', 'demand_yhat'] # Rename columns\n",
    "    forecast_2024['llave'] = combination # Add the combination column\n",
    "    # Add to the final predictions dataframe\n",
    "    final_prediction_2024 = pd.concat([final_prediction_2024, forecast_2024])\n",
    "    final_prediction_2024['demand_yhat'] = final_prediction_2024['demand_yhat'].apply(lambda x: 0 if x < 0 else x)\n",
    "    # # -----------------------------------------------------------------------------------\n",
    "    # # Do the same to generate de prophet_df, but with test data(2023) to compare results\n",
    "    # # -----------------------------------------------------------------------------------\n",
    "    # # Complete the missing weeks with 0\n",
    "    # first_date_test = df_combination_test['date_week'].min() # Get the first date in the dataframe\n",
    "    # last_date_test = df_combination_test['date_week'].max() # Get the last date in the dataframe\n",
    "    # # Create a dataframe with all the weeks between the year of the first date and the year of the last date\n",
    "    # df_dates_test = pd.DataFrame({'date_week': pd.date_range(start=f'{first_date_test.year}-01-08', end=f'{last_date_test.year}-12-31', freq='W-MON')})    \n",
    "    # df_combination_test = df_dates_test.merge(df_combination_test, on='date_week', how='left') # Merge the dataframes\n",
    "    # df_combination_test['quantity'] = df_combination_test['quantity'].fillna(0) # Replace NaN values with 0\n",
    "    # df_combination_test = df_combination_test[df_combination_test['date_week'] < '2024-01-01'] # Drop registers from 2024\n",
    "    \n",
    "    # # Create the prophet TEST dataframe\n",
    "    # dataframe_test = pd.DataFrame()\n",
    "    # dataframe_test['ds'] = df_combination_test['date_week']\n",
    "    # dataframe_test['y_true'] = df_combination_test['quantity']\n",
    "\n",
    "    # # Merge the forecast_2024 with the y_true values\n",
    "    # prediction = forecast[['ds', 'yhat']].merge(dataframe_test, on='ds', how='left')\n",
    "    # prediction = prediction[prediction['ds'] >= '2023-01-01']\n",
    "    # prediction['y_true'] = prediction['y_true'].fillna(0) # Fill NaN values with 0\n",
    "    # prediction['y_true'] = prediction['y_true'].astype(int)\n",
    "    # prediction['yhat'] = prediction['yhat'].apply(lambda x: 0 if x < 0 else x) # Replace negative values with 0\n",
    "    \n",
    "    \n",
    "    # # Calculate the rsme for test_set\n",
    "    # df_rsme = prediction.copy()\n",
    "    # rsme = np.sqrt(mean_squared_error(df_rsme['y_true'], df_rsme['yhat']))\n",
    "    \n",
    "    # # generate new column error with the abs(error)\n",
    "    # prediction['error'] = prediction['y_true'] - prediction['yhat']\n",
    "    # prediction['error'] = prediction['error'].apply(lambda x: abs(x))\n",
    "    # prediction['llave'] = combination\n",
    "    # final_prediction_2024_with_test_data = pd.concat([final_prediction_2024_with_test_data,prediction])\n",
    "    # rmse_por_llave = {\n",
    "    #     'llave': combination,\n",
    "    #     'rmse' : rsme\n",
    "    # }\n",
    "    # rmse_por_llave_resultados.append(rmse_por_llave)\n",
    "    with open(f'.././serialized_models/{str(combination)}.json', 'w') as file:\n",
    "        file.write(model_to_json(model))  # Save model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from prophet.serialize import model_to_json\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from datetime import date\n",
    "from llaves_more_then_q95 import llaves_more_then_q95\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "\n",
    "# Set the logging level for cmdstanpy to WARNING\n",
    "logging.getLogger('cmdstanpy').setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_sales_by_week = pd.read_parquet('./datasets/master_sales_by_week_curated.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add year column\n",
    "master_sales_by_week['year'] = master_sales_by_week['date'].apply(lambda x: x.strftime('%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total products_ids without sales: 266\n"
     ]
    }
   ],
   "source": [
    "# get product_ids without any sale\n",
    "total_sales_by_product_id = master_sales_by_week.groupby(['product_id'], as_index=False).agg({'quantity':'sum', })\n",
    "products_without_sales = total_sales_by_product_id[total_sales_by_product_id['quantity'] == 0]\n",
    "product_ids_without_sales = products_without_sales['product_id'].unique()\n",
    "print(f'Total products_ids without sales: {len(product_ids_without_sales)}')\n",
    "# remove products_id without any sale from the dataset\n",
    "master_sales_by_week = master_sales_by_week[~(master_sales_by_week['product_id'].isin(product_ids_without_sales))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combination</th>\n",
       "      <th>date</th>\n",
       "      <th>cod_fami</th>\n",
       "      <th>quantity</th>\n",
       "      <th>store_id</th>\n",
       "      <th>price_taxes_excluded</th>\n",
       "      <th>product_id</th>\n",
       "      <th>description_fami</th>\n",
       "      <th>description</th>\n",
       "      <th>event</th>\n",
       "      <th>discount</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201AA3</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>1010100</td>\n",
       "      <td>7554.62</td>\n",
       "      <td>229254.1001.EST</td>\n",
       "      <td>ACCESORIOS BEBE</td>\n",
       "      <td>PEZONERA GBC5103 EN SILICONA</td>\n",
       "      <td>NO EVENT</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  combination       date cod_fami  quantity store_id price_taxes_excluded  \\\n",
       "0      201AA3 2018-01-08      201         1  1010100              7554.62   \n",
       "\n",
       "        product_id description_fami                   description     event  \\\n",
       "0  229254.1001.EST  ACCESORIOS BEBE  PEZONERA GBC5103 EN SILICONA  NO EVENT   \n",
       "\n",
       "   discount  year  \n",
       "0         0  2018  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_sales_by_week.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Año:2018\n",
      "\t# Llaves Unicas: 6552\n",
      "Año:2019\n",
      "\t# Llaves Unicas: 6517\n",
      "Año:2020\n",
      "\t# Llaves Unicas: 5822\n",
      "Año:2021\n",
      "\t# Llaves Unicas: 5552\n",
      "Año:2022\n",
      "\t# Llaves Unicas: 5665\n",
      "Año:2023\n",
      "\t# Llaves Unicas: 5539\n",
      "Año:2024\n",
      "\t# Llaves Unicas: 4384\n"
     ]
    }
   ],
   "source": [
    "for year in master_sales_by_week['year'].unique():\n",
    "    n_unique_keys = master_sales_by_week[master_sales_by_week['date'].between(f'{year}-01-01',f'{year}-12-31')]['combination'].nunique()\n",
    "    print(f\"Año:{year}\\n\\t# Llaves Unicas: {n_unique_keys}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_keys_in_2022 = master_sales_by_week[master_sales_by_week['date'].between('2022-01-01','2022-12-31')]['combination'].unique()\n",
    "unique_keys_in_2023 = master_sales_by_week[master_sales_by_week['date'].between('2023-01-01','2023-12-31')]['combination'].unique()\n",
    "\n",
    "keys_to_forecast = list(set(unique_keys_in_2022) & set(unique_keys_in_2023)) # we going to forecast all the keys in 2022, and 2023 for testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataset for train (2018-2022) and test(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_sales_by_week_train = master_sales_by_week[master_sales_by_week['date'].between('2018-01-01','2022-12-31')]\n",
    "master_sales_by_week_test = master_sales_by_week[master_sales_by_week['date'].between('2023-01-01','2023-12-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4871 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4871/4871 [01:11<00:00, 68.23it/s]\n"
     ]
    }
   ],
   "source": [
    "weeks_of_information_by_combination = []\n",
    "for i in tqdm(keys_to_forecast):\n",
    "    df_temp = master_sales_by_week_train[master_sales_by_week_train['combination'] == i]\n",
    "    dict_temp = {\n",
    "        'combination' : i,\n",
    "        'n_weeks' : df_temp['date'].nunique()\n",
    "    }\n",
    "    weeks_of_information_by_combination.append(dict_temp)\n",
    "weeks_of_information_by_combination_df = pd.DataFrame(weeks_of_information_by_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Keys with less than 12 weeks of info: 477\n"
     ]
    }
   ],
   "source": [
    "keys_with_less_than_12_weeks_of_info = weeks_of_information_by_combination_df[weeks_of_information_by_combination_df['n_weeks'] <= 12]['combination'].unique()\n",
    "\n",
    "# keep just the keys present in 2022 and 2023\n",
    "master_sales_by_week_train = master_sales_by_week_train[master_sales_by_week_train['combination'].isin(keys_to_forecast)]\n",
    "master_sales_by_week_test = master_sales_by_week_test[master_sales_by_week_test['combination'].isin(keys_to_forecast)]\n",
    "# drop all the combination withot enoff information in train and test \n",
    "master_sales_by_week_train = master_sales_by_week_train[~(master_sales_by_week_train['combination'].isin(keys_with_less_than_12_weeks_of_info))]\n",
    "master_sales_by_week_test = master_sales_by_week_test[~(master_sales_by_week_test['combination'].isin(keys_with_less_than_12_weeks_of_info))]\n",
    "print(f'#Keys with less than 12 weeks of info: {len(keys_with_less_than_12_weeks_of_info)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combination</th>\n",
       "      <th>date</th>\n",
       "      <th>cod_fami</th>\n",
       "      <th>quantity</th>\n",
       "      <th>store_id</th>\n",
       "      <th>price_taxes_excluded</th>\n",
       "      <th>product_id</th>\n",
       "      <th>description_fami</th>\n",
       "      <th>description</th>\n",
       "      <th>event</th>\n",
       "      <th>discount</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201AA3</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>1010100</td>\n",
       "      <td>7554.62</td>\n",
       "      <td>229254.1001.EST</td>\n",
       "      <td>ACCESORIOS BEBE</td>\n",
       "      <td>PEZONERA GBC5103 EN SILICONA</td>\n",
       "      <td>NO EVENT</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201AA3</td>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>1010100</td>\n",
       "      <td>12596.64</td>\n",
       "      <td>206906.1001.EST</td>\n",
       "      <td>ACCESORIOS BEBE</td>\n",
       "      <td>RECOLECTOR IMP2476 INFANT X2</td>\n",
       "      <td>NO EVENT</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201AA3</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>201</td>\n",
       "      <td>4</td>\n",
       "      <td>1010100</td>\n",
       "      <td>10075.63</td>\n",
       "      <td>233106.1001.EST</td>\n",
       "      <td>ACCESORIOS BEBE</td>\n",
       "      <td>RECOLECTOR IMP2476 INFANT X2</td>\n",
       "      <td>NO EVENT</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201AA3</td>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>1010100</td>\n",
       "      <td>10075.63</td>\n",
       "      <td>206895.1001.EST</td>\n",
       "      <td>ACCESORIOS BEBE</td>\n",
       "      <td>ASPIRADOR NASAL BSL015 INFANT</td>\n",
       "      <td>NO EVENT</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201AA3</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>201</td>\n",
       "      <td>6</td>\n",
       "      <td>1010100</td>\n",
       "      <td>10075.63</td>\n",
       "      <td>233106.1001.EST</td>\n",
       "      <td>ACCESORIOS BEBE</td>\n",
       "      <td>VASO GBC5047 ENTRENADOR ANTIGT</td>\n",
       "      <td>TIJERETAZO I</td>\n",
       "      <td>30</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  combination       date cod_fami  quantity store_id price_taxes_excluded  \\\n",
       "0      201AA3 2018-01-08      201         1  1010100              7554.62   \n",
       "1      201AA3 2018-01-15      201         1  1010100             12596.64   \n",
       "2      201AA3 2018-01-22      201         4  1010100             10075.63   \n",
       "3      201AA3 2018-01-29      201         1  1010100             10075.63   \n",
       "4      201AA3 2018-02-05      201         6  1010100             10075.63   \n",
       "\n",
       "        product_id description_fami                     description  \\\n",
       "0  229254.1001.EST  ACCESORIOS BEBE    PEZONERA GBC5103 EN SILICONA   \n",
       "1  206906.1001.EST  ACCESORIOS BEBE    RECOLECTOR IMP2476 INFANT X2   \n",
       "2  233106.1001.EST  ACCESORIOS BEBE    RECOLECTOR IMP2476 INFANT X2   \n",
       "3  206895.1001.EST  ACCESORIOS BEBE   ASPIRADOR NASAL BSL015 INFANT   \n",
       "4  233106.1001.EST  ACCESORIOS BEBE  VASO GBC5047 ENTRENADOR ANTIGT   \n",
       "\n",
       "          event  discount  year  \n",
       "0      NO EVENT         0  2018  \n",
       "1      NO EVENT         0  2018  \n",
       "2      NO EVENT         0  2018  \n",
       "3      NO EVENT         0  2018  \n",
       "4  TIJERETAZO I        30  2018  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_sales_by_week_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4394 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 3994/4394 [10:54:12<14:00:22, 126.06s/it]python(25292) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████ | 3995/4394 [10:56:29<14:21:27, 129.54s/it]python(25486) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████ | 3996/4394 [10:58:48<14:37:11, 132.24s/it]python(25754) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████ | 3997/4394 [11:01:13<14:59:48, 135.99s/it]python(26041) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████ | 3998/4394 [11:03:53<15:46:46, 143.45s/it]python(26307) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████ | 3999/4394 [11:06:45<16:38:59, 151.75s/it]python(26771) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████ | 4000/4394 [11:09:34<17:11:21, 157.06s/it]python(27061) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████ | 4001/4394 [11:12:44<18:13:19, 166.92s/it]python(27544) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████ | 4002/4394 [11:16:47<20:40:27, 189.86s/it]python(28027) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████ | 4003/4394 [11:20:39<21:58:07, 202.27s/it]python(28426) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████ | 4004/4394 [11:24:14<22:20:57, 206.30s/it]python(28733) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████ | 4005/4394 [11:28:26<23:45:54, 219.93s/it]python(29145) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████ | 4006/4394 [11:33:26<26:17:00, 243.87s/it]python(29434) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████ | 4007/4394 [11:38:51<28:50:49, 268.35s/it]python(29971) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████ | 4008/4394 [11:44:18<30:38:36, 285.79s/it]python(30361) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████ | 4009/4394 [11:50:06<32:34:20, 304.57s/it]python(30954) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████▏| 4010/4394 [11:56:10<34:22:29, 322.27s/it]python(31716) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████▏| 4011/4394 [12:02:31<36:09:34, 339.88s/it]python(32033) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████▏| 4012/4394 [12:09:01<37:39:44, 354.93s/it]python(32640) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████▏| 4013/4394 [12:15:33<38:45:10, 366.17s/it]python(33151) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████▏| 4014/4394 [12:21:48<38:55:53, 368.83s/it]python(33439) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████▏| 4015/4394 [12:28:02<38:59:12, 370.32s/it]python(33785) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████▏| 4016/4394 [12:34:22<39:11:44, 373.29s/it]python(34131) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████▏| 4017/4394 [12:41:04<39:59:07, 381.82s/it]python(34565) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████▏| 4018/4394 [12:47:44<40:26:56, 387.28s/it]python(35002) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████▏| 4019/4394 [12:54:37<41:09:37, 395.14s/it]python(35663) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 91%|█████████▏| 4020/4394 [13:01:08<40:54:19, 393.74s/it]python(36099) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4021/4394 [13:07:50<41:03:41, 396.30s/it]python(36574) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4022/4394 [13:14:42<41:25:26, 400.88s/it]python(37025) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4023/4394 [13:21:20<41:14:12, 400.14s/it]python(37363) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4024/4394 [13:27:49<40:46:25, 396.72s/it]python(37685) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4025/4394 [13:34:33<40:52:59, 398.86s/it]python(38028) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4026/4394 [13:41:08<40:39:57, 397.82s/it]python(38322) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4027/4394 [13:47:39<40:20:31, 395.73s/it]python(38511) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4028/4394 [13:54:10<40:05:36, 394.36s/it]python(38898) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4029/4394 [14:00:57<40:22:57, 398.29s/it]python(39368) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4030/4394 [14:07:57<40:54:15, 404.55s/it]python(39758) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4031/4394 [14:15:20<41:58:14, 416.24s/it]python(40726) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4032/4394 [14:22:39<42:32:30, 423.07s/it]python(41049) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4033/4394 [14:29:50<42:40:10, 425.51s/it]python(41318) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4034/4394 [14:37:10<42:58:42, 429.79s/it]python(41642) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4035/4394 [14:44:31<43:12:00, 433.20s/it]python(42023) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4036/4394 [14:51:34<42:45:05, 429.90s/it]python(42402) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4037/4394 [14:59:02<43:11:03, 435.47s/it]python(42938) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4038/4394 [15:07:22<44:59:25, 454.96s/it]python(43392) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4039/4394 [15:14:37<44:16:08, 448.93s/it]python(43891) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4040/4394 [15:21:33<43:10:18, 439.04s/it]python(44274) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4041/4394 [15:28:07<41:43:02, 425.45s/it]python(44706) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4042/4394 [15:34:51<40:58:53, 419.13s/it]python(44986) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4043/4394 [15:41:35<40:25:08, 414.55s/it]python(45292) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4044/4394 [15:48:12<39:47:35, 409.30s/it]python(45541) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4045/4394 [15:55:09<39:52:55, 411.39s/it]python(45956) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 92%|█████████▏| 4046/4394 [16:01:54<39:36:13, 409.69s/it]python(46231) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "final_prediction_2023 = pd.DataFrame()\n",
    "dataframe_ytrue_ytest = pd.DataFrame()\n",
    "rmse_por_llave = pd.DataFrame()\n",
    "for combination in tqdm(master_sales_by_week_train['combination'].unique()):\n",
    "    sales_combination = master_sales_by_week_train[master_sales_by_week_train['combination'] == combination]\n",
    "    sales_combination = sales_combination[['date','combination','quantity','cod_fami']]\n",
    "\n",
    "    first_date = sales_combination['date'].min() # Get the first date in the dataframe\n",
    "    last_date = sales_combination['date'].max() # Get the last date in the dataframe\n",
    "\n",
    "    df_dates = pd.DataFrame({'date': pd.date_range(start=f'{first_date.year}-01-08', end='2022-12-31', freq='W-MON')})\n",
    "\n",
    "    sales_combination = df_dates.merge(sales_combination, on='date', how='left') # Merge the dataframes\n",
    "    sales_combination['quantity'] = sales_combination['quantity'].fillna(0) # Replace NaN values with 0\n",
    "    sales_combination = sales_combination[~(sales_combination['combination'].isnull())]\n",
    "\n",
    "    # Create the prophet dataframe\n",
    "    prophet_dataframe = pd.DataFrame()\n",
    "    prophet_dataframe['ds'] = sales_combination['date']\n",
    "    prophet_dataframe['y'] = sales_combination['quantity']\n",
    "    prophet_dataframe['y'] = prophet_dataframe['y'].astype(int)\n",
    "\n",
    "    n_unique_years = prophet_dataframe['ds'].dt.year.nunique() # Count the number of different years in the dataframe\n",
    "\n",
    "    # Train Model\n",
    "    model = Prophet(weekly_seasonality = 13)\n",
    "    model.fit(prophet_dataframe)\n",
    "\n",
    "    # -----------\n",
    "    # Test Model\n",
    "    # -----------\n",
    "    # Calculate how many weeks are missing from the last date in the dataframe to the last week of 2023\n",
    "    weeks = (date(2023, 12, 31) - prophet_dataframe['ds'].max().date()).days // 7\n",
    "\n",
    "    # Create a dataframe with the dates from the last date in the dataframe to the last week of 2023\n",
    "    sales_by_week_test = master_sales_by_week_test.copy()\n",
    "    df_combination_test = sales_by_week_test[sales_by_week_test['combination'] == combination][['date','quantity']] # get the y_true values of the combination selected\n",
    "\n",
    "    # future Dataframe\n",
    "    future_2023 = model.make_future_dataframe(periods=weeks, freq='W-MON')\n",
    "    future_2023 = future_2023[future_2023['ds'] >= '2023-01-01']\n",
    "    future_2023 = future_2023.merge(df_combination_test, right_on='date',left_on= 'ds', how = 'left')\n",
    "    del future_2023['date']\n",
    "    familia = combination[:3]\n",
    "    future_2023['familia'] = familia\n",
    "    future_2023['quantity'].fillna(0,inplace=True)\n",
    "\n",
    "    # Get Predictions\n",
    "    forecast = model.predict(future_2023) # Make the predictions\n",
    "    forecast_2023 = forecast[['ds', 'yhat']] # Get the predictions for 2023\n",
    "    forecast_2023.columns = ['date', 'demand_yhat'] # Rename columns\n",
    "    forecast_2023['llave'] = combination # Add the combination column\n",
    "    # Add to the final predictions dataframe\n",
    "    final_prediction_2023 = pd.concat([final_prediction_2023, forecast_2023])\n",
    "    final_prediction_2023['demand_yhat'] = final_prediction_2023['demand_yhat'].apply(lambda x: 0 if x < 0 else x)\n",
    "    final_prediction_2023['demand_yhat'] = final_prediction_2023['demand_yhat'].apply(lambda x: np.ceil(x))\n",
    "\n",
    "    # Generate dataframe with y_true and y_hat\n",
    "    df_combination_test.columns = ['date','y_true']\n",
    "    df_ytrue_yhat = final_prediction_2023.merge(df_combination_test,on= 'date', how = 'left')\n",
    "    df_ytrue_yhat['y_true'].fillna(0, inplace=True)\n",
    "    dataframe_ytrue_ytest = pd.concat([dataframe_ytrue_ytest, df_ytrue_yhat])\n",
    "    RMSE = np.sqrt(mean_squared_error(df_ytrue_yhat['y_true'], df_ytrue_yhat['demand_yhat']))\n",
    "    rmse_temp = {\n",
    "        'llave' : combination,\n",
    "        'rsme' : RMSE\n",
    "    }\n",
    "    df_rmse = pd.DataFrame([rmse_temp])\n",
    "    rmse_por_llave = pd.concat([rmse_por_llave,df_rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction_2023.to_parquet('./new_experiments/seasonality_52/final_prediction_2023.parquet', index = False)\n",
    "dataframe_ytrue_ytest.to_parquet('./new_experiments/seasonality_52/dataframe_ytrue_ytest.parquet', index = False)\n",
    "rmse_por_llave.to_parquet('./new_experiments/seasonality_52/rmse_por_llave.parquet', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llave</th>\n",
       "      <th>rsme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201AA3</td>\n",
       "      <td>2.961289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    llave      rsme\n",
       "0  201AA3  2.961289"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_por_llave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction_2023 = pd.DataFrame()\n",
    "rmse_por_llave = pd.DataFrame()\n",
    "test_model = True\n",
    "\n",
    "for combination in tqdm(llaves_con_informacion_historica_suficiente_para_forecast):\n",
    "\n",
    "    # Get the dataframe for the combination\n",
    "    df_combination = df_grouped_by_week[df_grouped_by_week['combination'] == combination]\n",
    "    df_combination = df_combination[['date_week','combination','quantity']]\n",
    "    \n",
    "    if combination in llaves_more_then_q95 and len(df_combination[df_combination['date_week'] >= '2022-01-01']) > 0: # si la llave esta en las llaves q95 y tiene data en el 2022, se entrena con data 2022, de lo contrario, se entra con todo lo disponible\n",
    "        df_combination = df_combination[df_combination['date_week'] >= '2022-01-01']\n",
    "    # df_combination_test = df_grouped_by_week_test[df_grouped_by_week_test['combination'] == combination][['date_week','quantity','campaign','discount_for_event']] # get the y_true values of the combination selected\n",
    "\n",
    "    familia = str(combination[:3])\n",
    "    df_discount_and_campaings = archivo_campanias[archivo_campanias['familia'] == familia]\n",
    "\n",
    "    # df_discount_and_campaings = df_grouped_by_week[df_grouped_by_week['date_week'] >= '2024-01-01']\n",
    "    # df_discount_and_campaings = df_discount_and_campaings[['combination','date_week','discount_for_event','campaign']]\n",
    "    # Complete the missing weeks with 0\n",
    "    first_date = df_combination['date_week'].min() # Get the first date in the dataframe\n",
    "    last_date = df_combination['date_week'].max() # Get the last date in the dataframe\n",
    "    \n",
    "    if test_model == True and first_date.year <= 2022:\n",
    "        # Create a dataframe with all the weeks between the year of the first date and the year of the last date\n",
    "        df_dates = pd.DataFrame({'date_week': pd.date_range(start=f'{first_date.year}-01-08', end=f'2022-12-31', freq='W-MON')})    \n",
    "\n",
    "        df_combination = df_dates.merge(df_combination, on='date_week', how='left') # Merge the dataframes\n",
    "        df_combination['quantity'] = df_combination['quantity'].fillna(0) # Replace NaN values with 0\n",
    "        df_combination = df_combination[~(df_combination['combination'].isnull())]\n",
    "        df_combination = df_combination.merge(df_discount_and_campaings, on='date_week', how='left') # Merge the dataframes\n",
    "\n",
    "        # Create the prophet dataframe\n",
    "        prophet_dataframe = pd.DataFrame()\n",
    "        prophet_dataframe['ds'] = df_combination['date_week']\n",
    "        prophet_dataframe['y'] = df_combination['quantity']\n",
    "        prophet_dataframe['campaign'] = df_combination['campaign']\n",
    "        prophet_dataframe['discount_for_event'] = df_combination['discount_for_event']\n",
    "        prophet_dataframe['y'] = prophet_dataframe['y'].astype(int)\n",
    "\n",
    "        n_unique_years = prophet_dataframe['ds'].dt.year.nunique() # Count the number of different years in the dataframe\n",
    "\n",
    "        # Create the model\n",
    "        if n_unique_years == 1:\n",
    "            model = Prophet(weekly_seasonality = 13)\n",
    "            model.add_regressor('campaign')\n",
    "            model.add_regressor('discount_for_event')\n",
    "\n",
    "        else:\n",
    "            model = Prophet(weekly_seasonality = 52)\n",
    "            model.add_regressor('campaign')\n",
    "            model.add_regressor('discount_for_event')\n",
    "            \n",
    "            \n",
    "        try:\n",
    "            model.fit(prophet_dataframe)\n",
    "            with open(f'./serialized_models/{str(combination)}.json', 'w') as file:\n",
    "                file.write(model_to_json(model))  # Save model\n",
    "            \n",
    "            \n",
    "            if test_model:\n",
    "                # Calculate how many weeks are missing from the last date in the dataframe to the last week of 2023\n",
    "                weeks = (date(2023, 12, 31) - prophet_dataframe['ds'].max().date()).days // 7\n",
    "\n",
    "                # Create a dataframe with the dates from the last date in the dataframe to the last week of 2023\n",
    "                df_grouped_by_week_test = df_grouped_by_week[df_grouped_by_week['date_week'].between('2023-01-01','2023-12-31')]\n",
    "                df_combination_test = df_grouped_by_week_test[df_grouped_by_week_test['combination'] == combination][['date_week','quantity']] # get the y_true values of the combination selected\n",
    "                df_combination_test = df_combination_test.merge(df_discount_and_campaings, on='date_week', how='left') # Merge the dataframes\n",
    "\n",
    "                future_2023 = model.make_future_dataframe(periods=weeks, freq='W-MON')\n",
    "                future_2023 = future_2023[future_2023['ds'] >= '2023-01-01']\n",
    "                future_2023 = future_2023.merge(df_combination_test, right_on='date_week',left_on= 'ds', how = 'left')\n",
    "                del future_2023['date_week']\n",
    "                future_2023['familia'] = familia\n",
    "                future_2023['campaign'].fillna(0,inplace=True)\n",
    "                future_2023['quantity'].fillna(0,inplace=True)\n",
    "                future_2023['discount_for_event'].fillna(0,inplace=True)\n",
    "                \n",
    "                \n",
    "                forecast = model.predict(future_2023) # Make the predictions\n",
    "                forecast_2023 = forecast[['ds', 'yhat']] # Get the predictions for 2023\n",
    "                forecast_2023.columns = ['date', 'demand_yhat'] # Rename columns\n",
    "                forecast_2023['llave'] = combination # Add the combination column\n",
    "                # Add to the final predictions dataframe\n",
    "                final_prediction_2023 = pd.concat([final_prediction_2023, forecast_2023])\n",
    "                final_prediction_2023['demand_yhat'] = final_prediction_2023['demand_yhat'].apply(lambda x: 0 if x < 0 else x)\n",
    "                final_prediction_2023['demand_yhat'] = final_prediction_2023['demand_yhat'].apply(lambda x: np.ceil(x))\n",
    "\n",
    "                X_test = df_grouped_by_week[df_grouped_by_week['combination'] == combination][['date_week','quantity']]\n",
    "                X_test.columns = ['date','y_true']\n",
    "                df_ytrue_yhat = final_prediction_2023.merge(X_test,on= 'date', how = 'left')\n",
    "                df_ytrue_yhat['y_true'].fillna(0, inplace=True)\n",
    "\n",
    "                RMSE = np.sqrt(mean_squared_error(df_ytrue_yhat['y_true'], df_ytrue_yhat['demand_yhat']))\n",
    "                dict_temp = {\n",
    "                    'llave' : combination,\n",
    "                    'rsme' : RMSE\n",
    "                }\n",
    "                df_rmse = pd.DataFrame([dict_temp])\n",
    "                rmse_por_llave = pd.concat([rmse_por_llave,df_rmse])\n",
    "        except Exception as e:\n",
    "            print(f'problems with this key: {combination}\\n{e}')\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    else:\n",
    "        print(combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with all data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for combination in tqdm(df_grouped_by_week['combination'].unique()):\n",
    "\n",
    "    # Get the dataframe for the combination\n",
    "    df_combination = df_grouped_by_week[df_grouped_by_week['combination'] == combination]\n",
    "    df_combination = df_combination[['date_week','combination','quantity']]\n",
    "    \n",
    "    if combination in llaves_more_then_q95 and len(df_combination[df_combination['date_week'] >= '2022-01-01']) > 0: # si la llave esta en las llaves q95 y tiene data en el 2023, se entrena con data 2023, de lo contrario, se entra con todo lo disponible\n",
    "        df_combination = df_combination[df_combination['date_week'] >= '2022-01-01']\n",
    "    # df_combination_test = df_grouped_by_week_test[df_grouped_by_week_test['combination'] == combination][['date_week','quantity','campaign','discount_for_event']] # get the y_true values of the combination selected\n",
    "\n",
    "    familia = str(combination[:3])\n",
    "    df_discount_and_campaings = archivo_campanias[archivo_campanias['familia'] == familia]\n",
    "\n",
    "    # df_discount_and_campaings = df_grouped_by_week[df_grouped_by_week['date_week'] >= '2024-01-01']\n",
    "    # df_discount_and_campaings = df_discount_and_campaings[['combination','date_week','discount_for_event','campaign']]\n",
    "    # Complete the missing weeks with 0\n",
    "    first_date = df_combination['date_week'].min() # Get the first date in the dataframe\n",
    "    last_date = df_combination['date_week'].max() # Get the last date in the dataframe\n",
    "    \n",
    "\n",
    "    # Create a dataframe with all the weeks between the year of the first date and the year of the last date\n",
    "    df_dates = pd.DataFrame({'date_week': pd.date_range(start=f'{first_date.year}-01-08', end=f'2023-12-31', freq='W-MON')})    \n",
    "\n",
    "    df_combination = df_dates.merge(df_combination, on='date_week', how='left') # Merge the dataframes\n",
    "    df_combination['quantity'] = df_combination['quantity'].fillna(0) # Replace NaN values with 0\n",
    "    df_combination = df_combination[~(df_combination['combination'].isnull())]\n",
    "    df_combination = df_combination.merge(df_discount_and_campaings, on='date_week', how='left') # Merge the dataframes\n",
    "\n",
    "    # Create the prophet dataframe\n",
    "    prophet_dataframe = pd.DataFrame()\n",
    "    prophet_dataframe['ds'] = df_combination['date_week']\n",
    "    prophet_dataframe['y'] = df_combination['quantity']\n",
    "    prophet_dataframe['campaign'] = df_combination['campaign']\n",
    "    prophet_dataframe['discount_for_event'] = df_combination['discount_for_event']\n",
    "    prophet_dataframe['y'] = prophet_dataframe['y'].astype(int)\n",
    "\n",
    "    n_unique_years = prophet_dataframe['ds'].dt.year.nunique() # Count the number of different years in the dataframe\n",
    "\n",
    "    # Create the model\n",
    "    if n_unique_years == 1:\n",
    "        model = Prophet(weekly_seasonality = 13)\n",
    "        model.add_regressor('campaign')\n",
    "        model.add_regressor('discount_for_event')\n",
    "\n",
    "    else:\n",
    "        model = Prophet(weekly_seasonality = 52)\n",
    "        model.add_regressor('campaign')\n",
    "        model.add_regressor('discount_for_event')\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        model.fit(prophet_dataframe)\n",
    "        with open(f'./serialized_models/{str(combination)}.json', 'w') as file:\n",
    "            file.write(model_to_json(model))  # Save model\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'problems with this key: {combination}\\n{e}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7240"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "len(glob('./serialized_models/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_prediction_2024 = pd.DataFrame()\n",
    "# final_prediction_2024_with_test_data = pd.DataFrame()\n",
    "# rmse_por_llave_resultados = []\n",
    "# # Get the list of combinations\n",
    "# for combination in tqdm(llaves_con_informacion_historica_suficiente_para_forecast):\n",
    "#     # Get the dataframe for the combination\n",
    "#     df_combination = df_grouped_by_week[df_grouped_by_week['combination'] == combination]\n",
    "#     if combination in llaves_more_then_q95 and len(df_combination[df_combination['date_week'] >= '2022-01-01']) > 0: # si la llave esta en las llaves q95 y tiene data en el 2022, se entrena con data 2022, de lo contrario, se entra con todo lo disponible\n",
    "#         df_combination = df_combination[df_combination['date_week'] >= '2022-01-01']\n",
    "#     # df_combination_test = df_grouped_by_week_test[df_grouped_by_week_test['combination'] == combination][['date_week','quantity','campaign','discount_for_event']] # get the y_true values of the combination selected\n",
    "#     df_discount_and_campaings = df_grouped_by_week[df_grouped_by_week['date_week'] >= '2024-01-01']\n",
    "#     df_discount_and_campaings = df_discount_and_campaings[['combination','date_week','discount_for_event','campaign']]\n",
    "#     # Complete the missing weeks with 0\n",
    "#     first_date = df_combination['date_week'].min() # Get the first date in the dataframe\n",
    "#     last_date = df_combination['date_week'].max() # Get the last date in the dataframe\n",
    "#     # Create a dataframe with all the weeks between the year of the first date and the year of the last date\n",
    "#     df_dates = pd.DataFrame({'date_week': pd.date_range(start=f'{first_date.year}-01-08', end=f'{last_date.year}-12-31', freq='W-MON')})    \n",
    "    \n",
    "#     df_combination = df_dates.merge(df_combination, on='date_week', how='left') # Merge the dataframes\n",
    "#     df_combination['quantity'] = df_combination['quantity'].fillna(0) # Replace NaN values with 0\n",
    "#     df_combination['campaign'] = df_combination['campaign'].fillna(0) # Replace NaN values with 0\n",
    "#     df_combination['discount_for_event'] = df_combination['discount_for_event'].fillna(0) # Replace NaN values with 0\n",
    "\n",
    "#     df_combination = df_combination[df_combination['date_week'] < '2023-12-31'] # Drop registers from 2024\n",
    "\n",
    "#     # Create the prophet dataframe\n",
    "#     prophet_dataframe = pd.DataFrame()\n",
    "#     prophet_dataframe['ds'] = df_combination['date_week']\n",
    "#     prophet_dataframe['y'] = df_combination['quantity']\n",
    "#     prophet_dataframe['campaign'] = df_combination['campaign']\n",
    "#     prophet_dataframe['discount_for_event'] = df_combination['discount_for_event']\n",
    "#     prophet_dataframe['y'] = prophet_dataframe['y'].astype(int)\n",
    "\n",
    "#     n_unique_years = prophet_dataframe['ds'].dt.year.nunique() # Count the number of different years in the dataframe\n",
    "\n",
    "#     # Create the model\n",
    "#     if n_unique_years == 1:\n",
    "#         model = Prophet(weekly_seasonality = 13)\n",
    "#         model.add_regressor('campaign')\n",
    "#         model.add_regressor('discount_for_event')\n",
    "\n",
    "#     else:\n",
    "#         model = Prophet(weekly_seasonality = 52)\n",
    "#         model.add_regressor('campaign')\n",
    "#         model.add_regressor('discount_for_event')\n",
    "        \n",
    "        \n",
    "#     model.fit(prophet_dataframe)\n",
    "\n",
    "#     # Calculate how many weeks are missing from the last date in the dataframe to the last week of 2023\n",
    "#     weeks = (date(2024, 12, 31) - prophet_dataframe['ds'].max().date()).days // 7\n",
    "#     # Create a dataframe with the dates from the last date in the dataframe to the last week of 2023\n",
    "#     future_2024 = model.make_future_dataframe(periods=weeks, freq='W-MON')\n",
    "#     future_2024 = future_2024[future_2024['ds'] >= '2024-01-01']\n",
    "#     future_2024 = future_2024.merge(df_combination_test, right_on='date_week',left_on= 'ds', how = 'left')\n",
    "#     del future_2024['date_week']\n",
    "#     future_2024[['quantity','campaign','discount_for_event']] = future_2024[['quantity','campaign','discount_for_event']].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "#     forecast = model.predict(future_2024) # Make the predictions\n",
    "#     forecast_2024 = forecast[['ds', 'yhat']] # Get the predictions for 2023\n",
    "#     forecast_2024.columns = ['date', 'demand_yhat'] # Rename columns\n",
    "#     forecast_2024['llave'] = combination # Add the combination column\n",
    "#     # Add to the final predictions dataframe\n",
    "#     final_prediction_2024 = pd.concat([final_prediction_2024, forecast_2024])\n",
    "#     final_prediction_2024['demand_yhat'] = final_prediction_2024['demand_yhat'].apply(lambda x: 0 if x < 0 else x)\n",
    "#     # # -----------------------------------------------------------------------------------\n",
    "#     # # Do the same to generate de prophet_df, but with test data(2023) to compare results\n",
    "#     # # -----------------------------------------------------------------------------------\n",
    "#     # # Complete the missing weeks with 0\n",
    "#     # first_date_test = df_combination_test['date_week'].min() # Get the first date in the dataframe\n",
    "#     # last_date_test = df_combination_test['date_week'].max() # Get the last date in the dataframe\n",
    "#     # # Create a dataframe with all the weeks between the year of the first date and the year of the last date\n",
    "#     # df_dates_test = pd.DataFrame({'date_week': pd.date_range(start=f'{first_date_test.year}-01-08', end=f'{last_date_test.year}-12-31', freq='W-MON')})    \n",
    "#     # df_combination_test = df_dates_test.merge(df_combination_test, on='date_week', how='left') # Merge the dataframes\n",
    "#     # df_combination_test['quantity'] = df_combination_test['quantity'].fillna(0) # Replace NaN values with 0\n",
    "#     # df_combination_test = df_combination_test[df_combination_test['date_week'] < '2024-01-01'] # Drop registers from 2024\n",
    "    \n",
    "#     # # Create the prophet TEST dataframe\n",
    "#     # dataframe_test = pd.DataFrame()\n",
    "#     # dataframe_test['ds'] = df_combination_test['date_week']\n",
    "#     # dataframe_test['y_true'] = df_combination_test['quantity']\n",
    "\n",
    "#     # # Merge the forecast_2024 with the y_true values\n",
    "#     # prediction = forecast[['ds', 'yhat']].merge(dataframe_test, on='ds', how='left')\n",
    "#     # prediction = prediction[prediction['ds'] >= '2023-01-01']\n",
    "#     # prediction['y_true'] = prediction['y_true'].fillna(0) # Fill NaN values with 0\n",
    "#     # prediction['y_true'] = prediction['y_true'].astype(int)\n",
    "#     # prediction['yhat'] = prediction['yhat'].apply(lambda x: 0 if x < 0 else x) # Replace negative values with 0\n",
    "    \n",
    "    \n",
    "#     # # Calculate the rsme for test_set\n",
    "#     # df_rsme = prediction.copy()\n",
    "#     # rsme = np.sqrt(mean_squared_error(df_rsme['y_true'], df_rsme['yhat']))\n",
    "    \n",
    "#     # # generate new column error with the abs(error)\n",
    "#     # prediction['error'] = prediction['y_true'] - prediction['yhat']\n",
    "#     # prediction['error'] = prediction['error'].apply(lambda x: abs(x))\n",
    "#     # prediction['llave'] = combination\n",
    "#     # final_prediction_2024_with_test_data = pd.concat([final_prediction_2024_with_test_data,prediction])\n",
    "#     # rmse_por_llave = {\n",
    "#     #     'llave': combination,\n",
    "#     #     'rmse' : rsme\n",
    "#     # }\n",
    "#     # rmse_por_llave_resultados.append(rmse_por_llave)\n",
    "#     with open(f'.././serialized_models/{str(combination)}.json', 'w') as file:\n",
    "#         file.write(model_to_json(model))  # Save model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
